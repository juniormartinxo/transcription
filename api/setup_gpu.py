#!/usr/bin/env python3
"""
Script para configurar ambiente para GPU (RTX 5070 Ti)
"""
import os
import sys
import subprocess
from pathlib import Path

def check_gpu():
    """Verifica se a GPU est√° dispon√≠vel"""
    try:
        import torch
        if torch.cuda.is_available():
            print(f"‚úÖ GPU detectada: {torch.cuda.get_device_name()}")
            print(f"‚úÖ CUDA version: {torch.version.cuda}")
            print(f"‚úÖ PyTorch version: {torch.__version__}")
            return True
        else:
            print("‚ùå GPU n√£o detectada")
            return False
    except ImportError:
        print("‚ùå PyTorch n√£o instalado")
        return False

def install_pytorch_gpu():
    """Instala PyTorch com suporte a GPU"""
    print("üì¶ Instalando PyTorch com suporte a GPU...")
    
    try:
        # Desinstalar vers√£o atual do PyTorch
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "torch", "torchaudio", "-y"], check=True)
        
        # Instalar PyTorch com CUDA 12.1 (compat√≠vel com RTX 5070 Ti)
        subprocess.run([
            sys.executable, "-m", "pip", "install", 
            "torch", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu121"
        ], check=True)
        
        print("‚úÖ PyTorch com GPU instalado")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Erro ao instalar PyTorch: {e}")
        return False

def setup_gpu_environment():
    """Configura o ambiente para usar GPU"""
    print("üîß Configurando ambiente para GPU...")
    
    # Configurar vari√°veis de ambiente para GPU
    os.environ['FORCE_CPU'] = 'false'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    # Configurar diret√≥rios locais
    os.environ['AUDIOS_DIR'] = './public/audios'
    os.environ['TRANSCRIPTIONS_DIR'] = './public/transcriptions'
    os.environ['LOG_FILE'] = './logs/app.log'
    
    print("‚úÖ Ambiente configurado para GPU")

def create_directories():
    """Cria diret√≥rios necess√°rios"""
    directories = [
        "public/audios",
        "public/transcriptions", 
        "logs"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Diret√≥rio criado: {directory}")

def check_env_file():
    """Verifica e atualiza arquivo .env"""
    env_file = Path(".env")
    
    if env_file.exists():
        # Ler conte√∫do atual
        with open(env_file, 'r') as f:
            content = f.read()
        
        # Atualizar FORCE_CPU para false
        if 'FORCE_CPU=true' in content:
            content = content.replace('FORCE_CPU=true', 'FORCE_CPU=false')
            with open(env_file, 'w') as f:
                f.write(content)
            print("‚úÖ FORCE_CPU configurado para false")
        else:
            print("‚úÖ FORCE_CPU j√° configurado para GPU")
    else:
        print("üìù Criando arquivo .env...")
        env_content = """# Configura√ß√µes da API de Transcri√ß√£o
HUGGING_FACE_HUB_TOKEN=seu_token_aqui
VERSION_MODEL=turbo
FORCE_CPU=false
AUDIOS_DIR=./public/audios
TRANSCRIPTIONS_DIR=./public/transcriptions
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log
"""
        with open(env_file, 'w') as f:
            f.write(env_content)
        print("‚úÖ Arquivo .env criado")

def test_gpu():
    """Testa se a GPU est√° funcionando"""
    print("üß™ Testando GPU...")
    
    try:
        import torch
        
        # Teste b√°sico de GPU
        if torch.cuda.is_available():
            device = torch.device("cuda")
            x = torch.randn(3, 3).to(device)
            y = torch.randn(3, 3).to(device)
            z = torch.mm(x, y)
            print("‚úÖ Teste de GPU bem-sucedido!")
            return True
        else:
            print("‚ùå GPU n√£o dispon√≠vel para teste")
            return False
    except Exception as e:
        print(f"‚ùå Erro no teste de GPU: {e}")
        return False

def run_application():
    """Executa a aplica√ß√£o"""
    print("üöÄ Iniciando aplica√ß√£o com GPU...")
    
    try:
        # Importar e executar a aplica√ß√£o
        from main import app
        import uvicorn
        
        print("üåê Servidor iniciado em: http://localhost:8000")
        print("üìö Documenta√ß√£o: http://localhost:8000/docs")
        print("üîç Health check: http://localhost:8000/health")
        print("‚èπÔ∏è  Para parar: Ctrl+C")
        
        uvicorn.run(
            app, 
            host="0.0.0.0", 
            port=8000, 
            reload=True,
            log_level="info"
        )
        
    except ImportError as e:
        print(f"‚ùå Erro ao importar aplica√ß√£o: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nüëã Aplica√ß√£o encerrada")
    except Exception as e:
        print(f"‚ùå Erro ao executar aplica√ß√£o: {e}")
        sys.exit(1)

def main():
    """Fun√ß√£o principal"""
    print("üöÄ Setup da API de Transcri√ß√£o para GPU")
    print("=" * 40)
    
    # Verificar GPU atual
    if not check_gpu():
        print("üì¶ Instalando PyTorch com suporte a GPU...")
        if not install_pytorch_gpu():
            print("‚ùå Falha ao instalar PyTorch com GPU")
            print("üí° Tente executar: python3 setup_cpu.py")
            sys.exit(1)
    
    # Testar GPU
    if not test_gpu():
        print("‚ö†Ô∏è  GPU n√£o est√° funcionando corretamente")
        print("üí° Tente executar: python3 setup_cpu.py")
        sys.exit(1)
    
    # Configura√ß√µes
    setup_gpu_environment()
    create_directories()
    check_env_file()
    
    print("\n" + "=" * 40)
    print("‚úÖ Setup conclu√≠do!")
    print("‚ö†Ô∏è  Lembre-se de configurar o HUGGING_FACE_HUB_TOKEN no arquivo .env")
    print("üöÄ Usando GPU para melhor performance")
    print("=" * 40)
    
    # Executar aplica√ß√£o
    run_application()

if __name__ == "__main__":
    main() 